


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-PQBQ3CV');
  </script>
  <!-- End Google Tag Manager -->

  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="google-site-verification" content="okUst94cAlWSsUsGZTB4xSS4UKTtRV8Nu5XZ9pdd3Aw" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Hardware agnostic training (preparation) &mdash; Lightning-Graphcore 0.1.0 documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://github.com/Lightning-AI/lightning-graphcore/prepare.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/sphinx_paramlinks.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <!-- Google Analytics -->
  
  <!-- End Google Analytics -->
  

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/UCity/UCity-Light.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/UCity/UCity-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/UCity/UCity-Semibold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/Inconsolata/Inconsolata.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <script defer src="https://use.fontawesome.com/releases/v6.1.1/js/all.js" integrity="sha384-xBXmu0dk1bEoiwd71wOonQLyH+VpgR1XcDH3rtxrLww5ajNTuMvBdL5SOiFZnNdp" crossorigin="anonymous"></script>

  <script src="https://unpkg.com/react@18/umd/react.development.js" crossorigin></script>
  <script src="https://unpkg.com/react-dom@18/umd/react-dom.development.js" crossorigin></script>
  <script src="https://unpkg.com/babel-standalone@6/babel.min.js"></script>
  <script src="_static/js/react/react.jsx" type="text/babel"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://lightning-graphcore.rtfd.io/en/latest/" aria-label="PyTorch Lightning">
      <!--  <img class="call-to-action-img" src="_static/images/logo-lightning-icon.png"/> -->
      </a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://lightning-graphcore.readthedocs.io/en/latest/introduction_guide.html">Get Started</a>
          </li>

          <li>
            <a href="https://www.Lightning-AI.ai/blog">Blog</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning.ai/docs/pytorch/stable/">
                  <span class="dropdown-title">PyTorch Lightning</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning.ai/docs/fabric/stable/">
                  <span class="dropdown-title">Lightning Fabric</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://torchmetrics.readthedocs.io/en/stable/">
                  <span class="dropdown-title">TorchMetrics</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-flash.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Flash</span>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://lightning-bolts.readthedocs.io/en/stable/">
                  <span class="dropdown-title">Lightning Bolts</span>
                </a>
            </div>
          </li>

          <!--<li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://lightning-graphcore.readthedocs.io/en/latest/#community-examples">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>-->

          

          <li>
            <a href="https://github.com/Lightning-AI/lightning-graphcore">GitHub</a>
          </li>

          <li>
            <a href="https://www.lightning.ai/">Lightning AI</a>
          </li>

        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  0.1.0
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Start here</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="readme.html">Lightning ⚡ GraphCore</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Hardware agnostic training (preparation)</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/prepare.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="hardware-agnostic-training-preparation">
<span id="ipu-prepare"></span><h1>Hardware agnostic training (preparation)<a class="headerlink" href="#hardware-agnostic-training-preparation" title="Permalink to this heading">¶</a></h1>
<p>To train on CPU/GPU/TPU without changing your code, we need to build a few good habits :)</p>
<hr class="docutils" />
<section id="delete-cuda-or-to-calls">
<h2>Delete .cuda() or .to() calls<a class="headerlink" href="#delete-cuda-or-to-calls" title="Permalink to this heading">¶</a></h2>
<p>Delete any calls to .cuda() or .to(device).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># before lightning</span>
<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">layer_1</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">x_hat</span> <span class="o">=</span> <span class="n">layer_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="c1"># after lightning</span>
<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x_hat</span> <span class="o">=</span> <span class="n">layer_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="init-tensors-using-tensor-to-and-register-buffer">
<h2>Init tensors using Tensor.to and register_buffer<a class="headerlink" href="#init-tensors-using-tensor-to-and-register-buffer" title="Permalink to this heading">¶</a></h2>
<p>When you need to create a new tensor, use <code class="docutils literal notranslate"><span class="pre">Tensor.to</span></code>.
This will make your code scale to any arbitrary number of GPUs or TPUs with Lightning.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># before lightning</span>
<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>


<span class="c1"># with lightning</span>
<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>The <a class="reference external" href="https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule" title="(in PyTorch Lightning v2.1.3)"><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code></a> knows what device it is on. You can access the reference via <code class="docutils literal notranslate"><span class="pre">self.device</span></code>.
Sometimes it is necessary to store tensors as module attributes. However, if they are not parameters they will
remain on the CPU even if the module gets moved to a new device. To prevent that and remain device agnostic,
register the tensor as a buffer in your modules’ <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method with <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer" title="(in PyTorch v2.1)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_buffer()</span></code></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;sigma&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
        <span class="c1"># you can now access self.sigma anywhere in your module</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="remove-samplers">
<h2>Remove samplers<a class="headerlink" href="#remove-samplers" title="Permalink to this heading">¶</a></h2>
<p><a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.distributed.DistributedSampler" title="(in PyTorch v2.1)"><code class="xref py py-class docutils literal notranslate"><span class="pre">DistributedSampler</span></code></a> is automatically handled by Lightning.</p>
</section>
<hr class="docutils" />
<section id="synchronize-validation-and-test-logging">
<h2>Synchronize validation and test logging<a class="headerlink" href="#synchronize-validation-and-test-logging" title="Permalink to this heading">¶</a></h2>
<p>When running in distributed mode, we have to ensure that the validation and test step logging calls are synchronized across processes.
This is done by adding <code class="docutils literal notranslate"><span class="pre">sync_dist=True</span></code> to all <code class="docutils literal notranslate"><span class="pre">self.log</span></code> calls in the validation and test step.
This ensures that each GPU worker has the same behaviour when tracking model checkpoints, which is important for later downstream tasks such as testing the best checkpoint across all workers.
The <code class="docutils literal notranslate"><span class="pre">sync_dist</span></code> option can also be used in logging calls during the step methods, but be aware that this can lead to significant communication overhead and slow down your training.</p>
<p>Note if you use any built in metrics or custom metrics that use <a class="reference external" href="https://torchmetrics.readthedocs.io/">TorchMetrics</a>, these do not need to be updated and are automatically handled for you.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="c1"># Add sync_dist=True to sync logging across all GPU workers (may have performance impact)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;validation_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sync_dist</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="c1"># Add sync_dist=True to sync logging across all GPU workers (may have performance impact)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;test_loss&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sync_dist</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>It is possible to perform some computation manually and log the reduced result on rank 0 as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>


<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">tensors</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tensors</span>


<span class="k">def</span> <span class="nf">on_test_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_gather</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>  <span class="c1"># free memory</span>

    <span class="c1"># When logging only on rank 0, don&#39;t forget to add</span>
    <span class="c1"># `rank_zero_only=True` to avoid deadlocks on synchronization.</span>
    <span class="c1"># caveat: monitoring this is unimplemented. see https://github.com/Lightning-AI/lightning/issues/15852</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">is_global_zero</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;my_reduced_metric&quot;</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">rank_zero_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<hr class="docutils" />
<section id="make-models-pickleable">
<h2>Make models pickleable<a class="headerlink" href="#make-models-pickleable" title="Permalink to this heading">¶</a></h2>
<p>It’s very likely your code is already <a class="reference external" href="https://docs.python.org/3/library/pickle.html">pickleable</a>,
in that case no change in necessary.
However, if you run a distributed model and get the following error:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">_launch</span><span class="p">(</span><span class="n">process_obj</span><span class="p">)</span>
<span class="n">File</span> <span class="s2">&quot;/net/software/local/python/3.6.5/lib/python3.6/multiprocessing/popen_spawn_posix.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">47</span><span class="p">,</span>
<span class="ow">in</span> <span class="n">_launch</span> <span class="n">reduction</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">process_obj</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
<span class="n">File</span> <span class="s2">&quot;/net/software/local/python/3.6.5/lib/python3.6/multiprocessing/reduction.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">60</span><span class="p">,</span> <span class="ow">in</span> <span class="n">dump</span>
<span class="n">ForkingPickler</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">protocol</span><span class="p">)</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
<span class="n">_pickle</span><span class="o">.</span><span class="n">PicklingError</span><span class="p">:</span> <span class="n">Can</span><span class="s1">&#39;t pickle &lt;function &lt;lambda&gt; at 0x2b599e088ae8&gt;:</span>
<span class="n">attribute</span> <span class="n">lookup</span> <span class="o">&lt;</span><span class="k">lambda</span><span class="o">&gt;</span> <span class="n">on</span> <span class="n">__main__</span> <span class="n">failed</span>
</pre></div>
</div>
<p>This means something in your model definition, transforms, optimizer, dataloader or callbacks cannot be pickled, and the following code will fail:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pickle</span>

<span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">some_object</span><span class="p">)</span>
</pre></div>
</div>
<p>This is a limitation of using multiple processes for distributed training within PyTorch.
To fix this issue, find your piece of code that cannot be pickled. The end of the stacktrace
is usually helpful.
ie: in the stacktrace example here, there seems to be a lambda function somewhere in the code
which cannot be pickled.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">_launch</span><span class="p">(</span><span class="n">process_obj</span><span class="p">)</span>
<span class="n">File</span> <span class="s2">&quot;/net/software/local/python/3.6.5/lib/python3.6/multiprocessing/popen_spawn_posix.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">47</span><span class="p">,</span>
<span class="ow">in</span> <span class="n">_launch</span> <span class="n">reduction</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">process_obj</span><span class="p">,</span> <span class="n">fp</span><span class="p">)</span>
<span class="n">File</span> <span class="s2">&quot;/net/software/local/python/3.6.5/lib/python3.6/multiprocessing/reduction.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">60</span><span class="p">,</span> <span class="ow">in</span> <span class="n">dump</span>
<span class="n">ForkingPickler</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="n">protocol</span><span class="p">)</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
<span class="n">_pickle</span><span class="o">.</span><span class="n">PicklingError</span><span class="p">:</span> <span class="n">Can</span><span class="s1">&#39;t pickle [THIS IS THE THING TO FIND AND DELETE]:</span>
<span class="n">attribute</span> <span class="n">lookup</span> <span class="o">&lt;</span><span class="k">lambda</span><span class="o">&gt;</span> <span class="n">on</span> <span class="n">__main__</span> <span class="n">failed</span>
</pre></div>
</div>
</section>
</section>


             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright Copyright (c) 2020-2023, Lightning-AI et al...

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Hardware agnostic training (preparation)</a><ul>
<li><a class="reference internal" href="#delete-cuda-or-to-calls">Delete .cuda() or .to() calls</a></li>
<li><a class="reference internal" href="#init-tensors-using-tensor-to-and-register-buffer">Init tensors using Tensor.to and register_buffer</a></li>
<li><a class="reference internal" href="#remove-samplers">Remove samplers</a></li>
<li><a class="reference internal" href="#synchronize-validation-and-test-logging">Synchronize validation and test logging</a></li>
<li><a class="reference internal" href="#make-models-pickleable">Make models pickleable</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  

  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/sphinx_highlight.js"></script>
         <script src="_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <!-- <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources"> -->
    <!-- <div class="container"> -->
      <!-- <div class="row"> -->
        <!--
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://lightning-graphcore.rtfd.io/en/latest">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://lightning-graphcore.readthedocs.io/en/latest/#tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://lightning-graphcore.readthedocs.io/en/latest/#community-examples">View Resources</a>
        </div>
        -->
      <!-- </div> -->
    <!-- </div> -->
  <!-- </div> -->

  <!--
  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://lightning-graphcore.rtfd.io/en/latest/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://lightning-graphcore.rtfd.io/en/latest/">PyTorch</a></li>
            <li><a href="https://lightning-graphcore.readthedocs.io/en/latest/introduction_guide.html">Get Started</a></li>
            <li><a href="https://lightning-graphcore.rtfd.io/en/latest/">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="https://www.Lightning-AI.ai/blog">Blog</a></li>
            <li><a href="https://github.com/Lightning-AI/lightning/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://lightning-graphcore.readthedocs.io/en/latest/#community-examples">Resources</a></li>
            <li><a href="https://lightning-graphcore.readthedocs.io/en/latest/#tutorials">Tutorials</a></li>
            <li><a href="https://lightning-graphcore.rtfd.io/en/latest">Docs</a></li>
            <li><a href="https://pytorch-lightning.slack.com" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/Lightning-AI/lightning-graphcore/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/PyTorchLightnin" target="_blank" class="twitter"></a>
            <a href="" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>
  -->

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. Read PyTorch Lightning's <a href="https://pytorchlightning.ai/privacy-policy">Privacy Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://lightning-graphcore.rtfd.io/en/latest/" aria-label="PyTorch Lightning"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://lightning-graphcore.readthedocs.io/en/latest/introduction_guide.html">Get Started</a>
          </li>

          <li>
            <a href="https://www.Lightning-AI.ai/blog">Blog</a>
          </li>

          <li class="resources-mobile-menu-title">
            Ecosystem
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://lightning.ai/docs/pytorch/stable/">PyTorch Lightning</a>
            </li>

            <li>
              <a href="https://lightning.ai/docs/fabric/stable/">Lightning Fabric</a>
            </li>

            <li>
              <a href="https://torchmetrics.readthedocs.io/en/stable/">TorchMetrics</a>
            </li>

            <li>
              <a href="https://lightning.ai/docs/fabric/stable/">Fabric</a>
            </li>
          </ul>

          <!--<li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://lightning-graphcore.readthedocs.io/en/latest/#community-examples">Developer Resources</a>
            </li>

            <li>
              <a href="https://lightning-graphcore.rtfd.io/en/latest/">About</a>
            </li>

            <li>
              <a href="">Models (Beta)</a>
            </li>

            <li>
              <a href="">Community</a>
            </li>

            <li>
              <a href="">Forums</a>
            </li>
          </ul>-->

          <li>
            <a href="https://github.com/Lightning-AI/lightning-graphcore">Github</a>
          </li>

          <li>
            <a href="https://www.lightning.ai/">Lightning.ai</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PQBQ3CV"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->
 </body>
</html>